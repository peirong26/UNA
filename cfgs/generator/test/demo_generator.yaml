device_generator:
out_dir: ~/results/demo_synth_random_shape
split: test # train or test
save_orig_for_visualize: True 



###############################
 
test_itr_limit: 100 #0  # n_subjects

num_deformations: 1 # n_deformations for each subj
all_contrasts: 10 # n_deformations for each deformation: >= 1, <= all_samples

mild_samples: 1
all_samples: 1 # n_samples within each subject 

###############################




dataset_names: ['AIBL', 'ATLAS'] # list of datasets
dataset_names: ['ADHD', 'HCP', 'AIBL', 'OASIS', 'ADNI', 'ADNI3', 'ATLAS'] # list of datasets
dataset_names: ['ADHD', 'HCP', 'AIBL', 'OASIS', 'ADNI', 'ADNI3', 'ATLAS', 'ISLES'] # list of datasets
dataset_names: ['AIBL'] #, 'HCP', 'AIBL', 'OASIS'] # list of datasets 
dataset_probs:


modality_probs: {
  'ADHD': {'T1': 1, 'T2': 0., 'FLAIR': 0., 'CT': 0., 'synth': 1.}, # healthy
  'HCP': {'T1': 1, 'T2': 0., 'FLAIR': 0., 'CT': 0., 'synth': 1.}, # healthy
  'AIBL': {'T1': 0.33, 'T2': 0.67, 'FLAIR': 1, 'CT': 0., 'synth': 1.}, # healthy
  'OASIS': {'T1': 0.5, 'T2': 0., 'FLAIR': 0., 'CT': 1, 'synth': 1.}, # healthy
  'ADNI': {'T1': 0.5, 'T2': 0., 'FLAIR': 0., 'CT': 0., 'synth': 1.}, # healthy / wmh
  'ADNI3': {'T1': 0., 'T2': 0., 'FLAIR': 0., 'CT': 0., 'synth': 1.}, # wmh 
  'ATLAS': {'T1': 0.5, 'T2': 0., 'FLAIR': 0., 'CT': 0., 'synth': 1.}, # stroke  
  'ISLES': {'T1': 0., 'T2': 0., 'FLAIR': 0.5, 'CT': 0., 'synth': 1.}, # isles  
} 


mix_synth_prob: 0. # TODO: blend synth with real images
dataset_option: brain_id

# setups for training/testing tasks 
task:
  encode_anomaly: True

  T1: True
  T2: False
  FLAIR: False
  CT: False 

  pathology: True

  super_resolution: False
  segmentation: False 
  registration: False
  surface: False
  distance: False 
  bias_fields: False
  contrastive: False

# setups for augmentation functions to apply
#augmentation_steps: {'synth': ['gamma', 'bias_field', 'resample', 'noise'], 'real': ['gamma', 'bias_field', 'resample', 'noise']} 
augmentation_steps: {'synth': ['resample'], 'real': ['resample']} 

# setups for generator
generator:

  size: [200, 200, 200] 

  augment: False

  photo_prob: 0.2
  max_rotation: 15
  max_shear: 0.2
  max_scaling: 0.2
  nonlin_scale_min: 0.03
  nonlin_scale_max: 0.06
  nonlin_std_max: 4
  bag_prob: 0.5
  bag_scale_min: 0.02
  bag_scale_max: 0.08
  bf_scale_min: 0.02
  bf_scale_max: 0.04
  bf_std_min: 0.1
  bf_std_max: 0.6
  gamma_std: 0.1
  noise_std_min: 0.05
  noise_std_max: 1.
  exvixo_prob: 0.25
  exvixo_prob_vs_photo: 0.66666666666666

  pv: True
  random_shift: False
  deform_one_hots: False
  integrate_deformation_fields: False
  produce_surfaces: False
  bspline_zooming: False  
  n_steps_svf_integration: 8
  nonlinear_transform: False

  ct_prob: 0
  flip_prob: 0.5
  
  pathology_prob: 1. # pathology_prob when synth
  random_shape_prob: 1. #1. #0. # initialize pathol shape from random noise (v.s. existing shapes)
  augment_pathology: True


  # UNA customized setups

  # mild-to-severe intra-subject aug params
  mild_samples: 1 #2
  all_samples: 1 #4
  all_contrasts: 1 # 4 # >= 1, <= all_samples
  num_deformations: 1




pathology_shape_generator:
  perlin_res: [2, 2, 2] # shape must be a multiple of res
  mask_percentile_min: 90
  mask_percentile_max: 99.6
  integ_method: dopri5 # choices=['dopri5', 'adams', 'rk4', 'euler'] 
  bc: neumann # choices=['neumann', 'cauchy', 'dirichlet', 'source_neumann', 'dirichlet_neumann'] 
  V_multiplier: 500
  dt: 0.1
  min_nt: 10 # >= 2
  max_nt: 20 # > 2
  pathol_thres: 0.2
  pathol_tol: 0.000001 # if pathol mean < tol, skip




# UNA customized setups

mild_generator:   
  bag_prob: 0.1
  bag_scale_min: 0.01
  bag_scale_max: 0.02
  bf_scale_min: 0.01
  bf_scale_max: 0.02
  bf_std_min: 0.
  bf_std_max: 0.02
  gamma_std: 0.01
  noise_std_min: 0.
  noise_std_max: 0.02 


severe_generator:   
  bag_prob: 0.5
  bag_scale_min: 0.02
  bag_scale_max: 0.08
  bf_scale_min: 0.02
  bf_scale_max: 0.04
  bf_std_min: 0.1
  bf_std_max: 0.6
  gamma_std: 0.1
  noise_std_min: 0.05
  noise_std_max: 1. 